from itertools import combinations
import numpy as np
import pandas as pd
import csv
import mimetypes
import math
import sys
import dask.dataframe as dd
from tqdm import tqdm
from numba import njit
import time
import datatable as dt
import xgboost as xgb
import matplotlib.pyplot as plt
import optuna #to search best parameters for signal background plot
import sys
import scipy
from scipy.stats import ks_2samp
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score, roc_curve, average_precision_score
from xgboost.sklearn import XGBClassifier
from matplotlib.patches import Patch, Circle # Correcting the patch error
from matplotlib.lines import Line2D
from matplotlib.colors import LogNorm
import pickle
from datetime import datetime
#Solicitar instrucciones desde terminal
# Solicitar al usuario si desea saltarse al graficado
skip_to_graph = int(input("Do you want to skip directly to the plotting of the calculated DataFrame? Yes=1, No=0:"))
if skip_to_graph == 1:
    # Solicitar el path del DataFrame calculado
    df_path = input("Enter the path of the previously calculated DataFrame:")
    results_df = pd.read_csv(df_path)
    df_combined=results_df
    Final_name=input('Enter the name of the .csv file that will be generated by this code: ')
    Final_name = Final_name + '.csv'
else:
 mimetypes.add_type('lhco', '.lhco')
 mimetypes.add_type('csv', '.csv')

# Ruta del archivo LHCO

 signal_path=input( 'Enter the path of your SIGNAL file, it can be in .lhco or .csv formats: \n')
 a1=input("The signal file is filtered with the final state you want to analyze. If you already have it filtered and want to skip this step, enter 1. If you don't have it filtered yet, enter 0: ")
 pathsback = []
 evit=int(input("If you already have a background with the calculated database, enter 1 and the path you will enter next will be that one, otherwise enter 0: ")) 

 print('Enter the path of your BACKGROUND file, it can be in .lhco or .csv formats: (press enter to continue): \n')
 while True:
        paths = input('Path: ')
        if paths == '':
                break
        pathsback.append(paths)
#print(pathsback)
 print('\n')
 Final_name=input('Enter the name of the .csv file that will be generated by this code: ')
 Final_name = Final_name + '.csv'
 dfbg = pd.DataFrame()
 for i in pathsback:
    mime_type, encoding = mimetypes.guess_type(i)

    # Verificamos si el tipo de archivo es 'lhco'
    if mime_type == 'lhco':
        data=pd.read_csv(i,sep=r'\s+')
    if mime_type == 'csv':
    	data=pd.read_csv(i)

    # Concatenar las bases de datos
    dfbg = pd.concat([dfbg, data], ignore_index=True)
 if evit != 1:
        mask = dfbg['#'] == 0
# Actualiza todas las columnas excepto la columna '#'
        dfbg.loc[mask, dfbg.columns != '#'] = 10.0
 filtered_dfbg = pd.DataFrame(dfbg)
 dfbg=[]
 mime_type, encoding = mimetypes.guess_type(signal_path)
# Verificamos si el tipo de archivo es 'lhco'
 if mime_type == 'lhco':
    dfsg=pd.read_csv(signal_path,sep=r'\s+')

 print('\n')
 if mime_type == 'csv':
    dfsg=pd.read_csv(signal_path)
 mask = dfsg['#'] == 0
# Actualiza todas las columnas excepto la columna '#'
 dfsg.loc[mask, dfsg.columns != '#'] = 10.0
 filtered_dfsg = pd.DataFrame(dfsg)
 dfsg=[]
 print('\n')
# Convertir nombres de partículas a números
 particulas_dict = {
    'a': 0,
    'e-': 1,
    'mu-': 2,
    't': 3,
    'j': 4,
    'MET': 6,
    'e+': 5,
    'mu+': 7,
    'jb':8
 }
 particulas_dict_inv = {v: k for k, v in particulas_dict.items()}
 def expand_and_swap_tuples(tuples_list):
    expanded_list = []
    for t in tuples_list:
        for i in range(1, t[0] + 1):
            expanded_list.append((t[1], i))
    return expanded_list
#Esta función se utiliza para los nombres de las columnas 
 def tupla_a_cadena(tupla):
    if isinstance(tupla, tuple):
        return '(' + ', '.join(tupla_a_cadena(sub) for sub in tupla) + ')'
    else:
        return str(tupla)
# Función para determinar detalles extra de la partícula.
 def determinar_valor(x):
    if x == 6:
        return 0
    elif x == 1:
        return -1
    elif x == 2:
        return -1
    elif x == 0:
        return 0
    elif x == 3:
        return 0
    elif x == 4:
        return 0
    elif x == 5:
        return 1
    elif x == 7:
        return 1
    elif x == 8:
        return 1
    else:
        return 0

 def revertir_tuplas(tuplas):
    resultado = []
    for t in tuplas:
        if len(t) == 1:
            particula = particulas_dict[t[0]]
            resultado.append((particula, 1, determinar_valor(particula)))
        else:
            particula = particulas_dict[t[0]]
            referencia = t[1]
            if referencia == 'leading':
                indice = 1
            elif referencia == 'subleading':
                indice = 2
            elif referencia == 'tertiary':
                indice = 3
            elif referencia == 'quaternary':
                indice = 4
            elif referencia == 'quinary':
                indice = 5
            resultado.append((particula, indice, determinar_valor(particula)))
        # Aplicar la condición adicional
    resultado_mod = [(4 if x == 8 else 1 if x == 5 else 2 if x == 7 else x, y, z) for (x, y, z) in resultado]
    return resultado_mod

 def transformar_tuplas(tuplas):
    resultado = []
    for t in tuplas:
        particula = particulas_dict_inv[t[0]]
        if t[0] == 6:
            resultado.append((particula,))
        else:
            if t[1] == 1:
                referencia = 'leading'
            elif t[1] == 2:
                referencia = 'subleading'
            elif t[1] == 3:
                referencia = 'tertiary'
            elif t[1] == 4:
                referencia = 'quaternary'
            elif t[1] == 5:
                referencia = 'quinary'
            resultado.append((particula, referencia))
    return resultado
 if a1== "0":
  print("Please enter the particles you want to analyze in the final state(this list is for the filtered of the signal).")
  print("First, enter the number of particles (n) followed by the name of the particle.")
  print("The available particles are: a(photon), e-(electron), e+(positron), mu+(antimuon), mu-(muon), t(tau), j(jet) and jb(jet b tagged)\n")
  print("Example: 2 a \n")

# Solicitar entrada del usuario
  lista = []

  while True:
    elemento = input("Particle: ")

    if elemento.lower() == '':
        break

    lista.append(elemento)

  lista = [(int(e.split()[0]), e.split()[1]) for e in lista]


  lista_num = [(cantidad, particulas_dict[particula]) for cantidad, particula in lista]
  lista_num.append((1, 6))


  lista_num = expand_and_swap_tuples(lista_num)

  lista_num_names=transformar_tuplas(lista_num)
  print(lista_num_names)
  lista_num = [(x, y, determinar_valor(x)) for (x, y) in lista_num]
# Cambiar los valores de antimuon (7) a 2 y positron (5) a 1
  lista_num_mod = [(4 if x == 8 else 1 if x == 5 else 2 if x == 7 else x, y, z) for (x, y, z) in lista_num]
#print(lista_num_mod)
#Filtrado de LHCO
  def procesar_en_bloques(df, num_list, bloque_tamano=10000):
    total_filas = len(df)
    resultados = []
    inicio = 0

    while inicio < total_filas:
        fin = inicio + bloque_tamano

        # Asegúrate de no cortar eventos
        while fin < total_filas and df.iloc[fin]['#'] != 0:
            fin += 1

        bloque = df.iloc[inicio:fin]
        resultado_bloque = filtrar_eventos(bloque, num_list)
        resultados.append(resultado_bloque)
        inicio = fin

    return pd.concat(resultados, ignore_index=True)

  def filtrar_eventos(df, num_list):
    try:
        event_indices = []
        current_event = []
        current_event_number = None
        num_list_first_elements = [t[0] for t in num_list]
        num_list_first_third_elements = [(t[0], t[2]) for t in num_list]
        total_rows = len(df)
        with tqdm(total=total_rows, desc="Filtering events") as pbar:
            for i, row in df.iterrows():
                if row['#'] == 0:
                    if current_event:
                        event_typ_counts = [r['typ'] for r in current_event]
                        event_typ_ntrk_tuples = [(r['typ'], r['ntrk']) for r in current_event]
                        if all(event_typ_counts.count(num) >= num_list_first_elements.count(num) for num in set(num_list_first_elements)):
                            if all(event_typ_ntrk_tuples.count(tup) >= num_list_first_third_elements.count(tup) for tup in num_list_first_third_elements if tup[0] in [1, 2]):
                                event_indices.extend(current_event)
                    current_event = []
                    current_event_number = row['#']
                current_event.append(row)
                pbar.update(1)
            if current_event:
                event_typ_counts = [r['typ'] for r in current_event]
                event_typ_ntrk_tuples = [(r['typ'], r['ntrk']) for r in current_event]
                if all(event_typ_counts.count(num) >= num_list_first_elements.count(num) for num in set(num_list_first_elements)):
                    if all(event_typ_ntrk_tuples.count(tup) >= num_list_first_third_elements.count(tup) for tup in num_list_first_third_elements if tup[0] in [1, 2]):
                        event_indices.extend(current_event)
        return pd.DataFrame(event_indices)
    except Exception as e:
        print(f"Error during event filtering: {e}")
        return pd.DataFrame()
  print("Start the filtering of data.")
  filtered_dfsg = procesar_en_bloques(filtered_dfsg, lista_num_mod, bloque_tamano=100000)
 print("Please enter the particles you want to analyze in the final state.")
 print("First, enter the number of particles (n) followed by the name of the particle.")
 print("The available particles are: a(photon), e-(electron), e+(positron), mu+(antimuon), mu-(muon), t(tau), j(jet) and jb(jet b tagged)\n")
 print("Example: 2 a \n")

# Solicitar entrada del usuario
 lista = []

 while True:
    elemento = input("Particle: ")

    if elemento.lower() == '':
        break

    lista.append(elemento)

 lista = [(int(e.split()[0]), e.split()[1]) for e in lista]
 lista_num = [(cantidad, particulas_dict[particula]) for cantidad, particula in lista]
 lista_num.append((1, 6))
 lista_num = expand_and_swap_tuples(lista_num)
 lista_num_names=transformar_tuplas(lista_num)
 print(lista_num_names)
 comb_pares_names = list(combinations(lista_num_names, 2))
 comb_trios_names = list(combinations(lista_num_names, 3))
 comb_cuartetos_names = list(combinations(lista_num_names, 4))
 lista_num = [(x, y, determinar_valor(x)) for (x, y) in lista_num]
# Cambiar los valores de antimuon (7) a 2 y positron (5) a 1
 lista_num_mod = [(4 if x == 8 else 1 if x == 5 else 2 if x == 7 else x, y, z) for (x, y, z) in lista_num]
# Obtener todas las combinaciones de 2, 3 y 4 elementos
 combinaciones_pares = list(combinations(lista_num_mod, 2))
 combinaciones_trios = list(combinations(lista_num_mod, 3))
 combinaciones_cuartetos = list(combinations(lista_num_mod, 4))
 print("The combinations were made.")
 func_1=input("Do you want to add the calculation of invariant masses? Yes (1), No (0): ")
 combinaciones_pares_minv=[]
 comb_pares_names_minv=[]
 combinaciones_trios_minv=[]
 comb_trios_names_minv=[]
 combinaciones_cuartetos_minv=[]
 comb_cuartetos_names_minv=[]
 if func_1=="1":
        print ("The available pair combinations for invariant mass are:")
        for i in comb_pares_names:
                 print (i)  
        option_1=input("Do you want to modify (remove) any of these combinations? Yes (1), No (0):")
        comb_pares_names_minv = comb_pares_names.copy()
        if option_1=="1":
          while True:
            print("Copy and paste the combination you want to remove below (or type 'exit' to finish):")
            comb_to_remove = input()
            if comb_to_remove.lower() == 'exit':
                break
            try:
                comb_to_remove = eval(comb_to_remove)
                if comb_to_remove in comb_pares_names_minv:
                    comb_pares_names_minv.remove(comb_to_remove)
                    print(f"Combination {comb_to_remove} deleted.")
                else:
                    print("The combination is not in the list.")
            except:
                print("Invalid combination format. Please try again.")
        
        comb_pares_names_minv = tuple(comb_pares_names_minv)
        print("New list of combinations:", comb_pares_names_minv)
        combinaciones_pares_minv = [revertir_tuplas(par) for par in comb_pares_names_minv]
        #print("Nueva lista de combinaciones:", combinaciones_pares_minv)
        
        print ("The available trio combinations for invariant mass are:")
        for i in comb_trios_names:
                  print (i)  
        option_1=input("Do you want to modify (remove) any of these combinations? Yes (1), No (0):")
        comb_trios_names_minv = comb_trios_names.copy()
        if option_1=="1":
          while True:
            print("Copy and paste the combination you want to remove below (or type 'exit' to finish):")
            comb_to_remove = input()
            if comb_to_remove.lower() == 'exit':
                break
            try:
                comb_to_remove = eval(comb_to_remove)
                if comb_to_remove in comb_trios_names_minv:
                    comb_trios_names_minv.remove(comb_to_remove)
                    print(f"Combination {comb_to_remove} deleted.")
                else:
                    print("The combination is not in the list.")
            except:
                print("Invalid combination format. Please try again.")
        
        comb_trios_names_minv = tuple(comb_trios_names_minv)
        print("New list of combinations:", comb_trios_names_minv)
        combinaciones_trios_minv = [revertir_tuplas(par) for par in comb_trios_names_minv]
        #print("Nueva lista de combinaciones:", combinaciones_trios_minv)
       
        print ("The available quartet combinations for invariant mass are:")
        for i in comb_cuartetos_names:
                 print (i)  
        option_1=input("Do you want to modify (remove) any of these combinations? Yes (1), No (0):")
        comb_cuartetos_names_minv = comb_cuartetos_names.copy()
        if option_1=="1":
          while True:
            print("Copy and paste the combination you want to remove below (or type 'exit' to finish):")
            comb_to_remove = input()
            if comb_to_remove.lower() == 'exit':
                break
            try:
                comb_to_remove = eval(comb_to_remove)
                if comb_to_remove in comb_cuartetos_names_minv:
                    comb_cuartetos_names_minv.remove(comb_to_remove)
                    print(f"Combination {comb_to_remove} deleted.")
                else:
                    print("The combination is not in the list.")
            except:
                print("Invalid combination format. Please try again.")
        comb_cuartetos_names_minv = tuple(comb_cuartetos_names_minv)
        print("New list of combinations:", comb_cuartetos_names_minv)
        combinaciones_cuartetos_minv = [revertir_tuplas(par) for par in comb_cuartetos_names_minv]
        #print("Nueva lista de combinaciones:", combinaciones_cuartetos_minv)
 func_2=input("Do you want to add the calculation of transverse masses? Yes (1), No (0): ")
 combinaciones_pares_mtrans=[]
 comb_pares_names_mtrans=[]
 if func_2=="1":
        print ("The available pair combinations for transverse mass are:")
        for i in comb_pares_names:
                print (i)  
        option_1=input("Do you want to modify (remove) any of these combinations? Yes (1), No (0):")
        comb_pares_names_mtrans = comb_pares_names.copy()
        if option_1=="1":
          while True:
            print("Copy and paste the combination you want to remove below (or type 'exit' to finish):")
            comb_to_remove = input()
            if comb_to_remove.lower() == 'exit':
                break
            try:
                comb_to_remove = eval(comb_to_remove)
                if comb_to_remove in comb_pares_names_mtrans:
                    comb_pares_names_mtrans.remove(comb_to_remove)
                    print(f"Combination {comb_to_remove} deleted.")
                else:
                    print("The combination is not in the list.")
            except:
                print("Invalid combination format. Please try again.")
        
          comb_pares_names_mtrans = tuple(comb_pares_names_mtrans)
          print("New list of combinations:", comb_pares_names_mtrans)
          combinaciones_mtrans = [revertir_tuplas(par) for par in comb_pares_names_mtrans]
         #print("Nueva lista de combinaciones:", combinaciones_pares_mtrans)
 func_3=input("Do you want to add the calculation of DeltaR? Yes (1), No (0):")
 combinaciones_pares_deltar=[]
 comb_pares_names_deltar=[]
 if func_3=="1":
        print ("The available pair combinations for DeltaR calculation are:")
        for i in comb_pares_names:
                print (i)  
        option_1=input("Do you want to modify (remove) any of these combinations? Yes (1), No (0):")
        comb_pares_names_deltar = comb_pares_names.copy()
        if option_1=="1":
          while True:
            print("Copy and paste the combination you want to remove below (or type 'exit' to finish):")
            comb_to_remove = input()
            if comb_to_remove.lower() == 'exit':
                break
            try:
                comb_to_remove = eval(comb_to_remove)
                if comb_to_remove in comb_pares_names_deltar:
                    comb_pares_names_deltar.remove(comb_to_remove)
                    print(f"Combination {comb_to_remove} deleted.")
                else:
                    print("The combination is not in the list.")
            except:
                print("Invalid combination format. Please try again.")
        
        comb_pares_names_deltar = tuple(comb_pares_names_deltar)
        print("New list of combinations:", comb_pares_names_deltar)
        combinaciones_pares_deltar = [revertir_tuplas(par) for par in comb_pares_names_deltar]
          #print("Nueva lista de combinaciones:", combinaciones_pares_deltar)
 func_5=input("Do you want to add the calculation of the Ratio between Pt's? Yes (1), No (0): ")
 combinaciones_pares_ratiopt=[]
 comb_pares_names_ratiopt=[]
 if func_5=="1":
        print ("The available pair combinations for the calculation of the Ratio between Pt's are:")
        for i in comb_pares_names:
                print (i)  
        option_1=input("Do you want to modify (remove) any of these combinations? Yes (1), No (0):")
        comb_pares_names_ratiopt = comb_pares_names.copy()
        if option_1=="1":
          while True:
            print("Copy and paste the combination you want to remove below (or type 'exit' to finish):")
            comb_to_remove = input()
            if comb_to_remove.lower() == 'exit':
                break
            try:
                comb_to_remove = eval(comb_to_remove)
                if comb_to_remove in comb_pares_names_ratiopt:
                    comb_pares_names_ratiopt.remove(comb_to_remove)
                    print(f"Combination {comb_to_remove} deleted.")
                else:
                    print("The combination is not in the list.")
            except:
                print("Invalid combination format. Please try again.")
        
        comb_pares_names_ratiopt = tuple(comb_pares_names_ratiopt)
        print("New list of combinations:", comb_pares_names_ratiopt)
        combinaciones_pares_ratiopt = [revertir_tuplas(par) for par in comb_pares_names_ratiopt]
 func_6=input("Do you want to add the calculation of the Product of Etas in pairs? Yes (1), No (0): ")
 combinaciones_pares_prdeta=[]
 comb_pares_names_prdeta=[]
 if func_6=="1":
        print ("The available pair combinations for the calculation of the Product of Etas are:")
        for i in comb_pares_names:
                print (i)  
        option_1=input("Do you want to modify (remove) any of these combinations? Yes (1), No (0):")
        comb_pares_names_prdeta = comb_pares_names.copy()
        if option_1=="1":
          while True:
            print("Copy and paste the combination you want to remove below (or type 'exit' to finish):")
            comb_to_remove = input()
            if comb_to_remove.lower() == 'exit':
                break
            try:
                comb_to_remove = eval(comb_to_remove)
                if comb_to_remove in comb_pares_names_prdeta:
                    comb_pares_names_prdeta.remove(comb_to_remove)
                    print(f"Combination {comb_to_remove} deleted.")
                else:
                    print("The combination is not in the list.")
            except:
                print("Invalid combination format. Please try again.")
        
        comb_pares_names_prdeta = tuple(comb_pares_names_prdeta)
        print("New list of combinations:", comb_pares_names_prdeta )
        combinaciones_pares_prdeta = [revertir_tuplas(par) for par in comb_pares_names_prdeta]
 func_7=input("Do you want to add the calculation of the Eta separation in pairs? Yes (1), No (0): ")
 combinaciones_pares_difeta=[]
 comb_pares_names_difeta=[]
 if func_7=="1":
        print ("The available pair combinations for the calculation of Eta separation are:")
        for i in comb_pares_names:
                print (i)  
        option_1=input("Do you want to modify (remove) any of these combinations? Yes (1), No (0):")
        comb_pares_names_difeta = comb_pares_names.copy()
        if option_1=="1":
          while True:
            print("Copy and paste the combination you want to remove below (or type 'exit' to finish):")
            comb_to_remove = input()
            if comb_to_remove.lower() == 'exit':
                break
            try:
                comb_to_remove = eval(comb_to_remove)
                if comb_to_remove in comb_pares_names_difeta:
                    comb_pares_names_difeta.remove(comb_to_remove)
                    print(f"Combination {comb_to_remove} deleted.")
                else:
                    print("The combination is not in the list.")
            except:
                print("Invalid combination format. Please try again.")
        
        comb_pares_names_difeta = tuple(comb_pares_names_difeta)
        print("New list of combinations:", comb_pares_names_difeta )
        combinaciones_pares_difeta = [revertir_tuplas(par) for par in comb_pares_names_difeta]
 func_4=input("Do you want to add the calculation of the number of jets per event? Yes (1), No (0): ")
#Funcion para no.jets
 def Num_jets(evento):
    jets=evento[evento['typ']== 4]
    njets=len(jets)
    return njets
#Vector de momento
 @njit
 def momentum_vector(pt, phi, eta):
    pt_x = pt * np.cos(phi)
    pt_y = pt * np.sin(phi)
    pt_z = pt * np.sinh(eta)
    return pt_x, pt_y, pt_z

#OBTENCIÓN PT, ETA, PHI
 def phi_part(evento, listapart):
    prt = evento[evento['typ'] == listapart[0]]
    
    # Condición extra para typ 1 o 2
    if listapart[0] in [1, 2]:
        prt = prt[prt['ntrk'] == listapart[2]]
    # Condición extra para typ 4
    if listapart[0] == 4:
        if listapart[2] == 0:
            prt = prt[prt['btag'] == listapart[2]]
        elif listapart[2] == 1:
            prt = prt[prt['btag'].isin([1, 2])]
    if not prt.empty:
        posicion = listapart[1] - 1
        if posicion < len(prt):
            phi_prt = prt.iloc[posicion]['phi']
            return phi_prt
        else:
            return 0 
    
    return 0


 def eta_part(evento,listapart):
    prt=evento[evento['typ']==listapart[0]]
    if listapart[0] in [1, 2]:
        prt = prt[prt['ntrk'] == listapart[2]]
        # Condición extra para typ 4
    if listapart[0] == 4:
        if listapart[2] == 0:
            prt = prt[prt['btag'] == listapart[2]]
        elif listapart[2] == 1:
            prt = prt[prt['btag'].isin([1, 2])]
    if not prt.empty:
        posicion = listapart[1] - 1
        if posicion < len(prt):
            eta_prt = prt.iloc[posicion]['eta']
            return eta_prt
        else:
            return 0 
    return 0

 def pt_part(evento,listapart):
    prt=evento[evento['typ']==listapart[0]]
    if listapart[0] in [1, 2]:
        prt = prt[prt['ntrk'] == listapart[2]]
        # Condición extra para typ 4
    if listapart[0] == 4:
        if listapart[2] == 0:
            prt = prt[prt['btag'] == listapart[2]]
        elif listapart[2] == 1:
            prt = prt[prt['btag'].isin([1, 2])]
    if not prt.empty:
        posicion = listapart[1] - 1
        if posicion < len(prt):
            pt_prt = prt.iloc[posicion]['pt']
            return pt_prt
        else:
            return 0 
    return 0
#MASA TRANSVERSA
 @njit
 def calcular_masa_transversa_numba(pt1, phi1, eta1, pt2, phi2, eta2):
    pt1_x, pt1_y, _ = momentum_vector(pt1, phi1, eta1)
    pt2_x, pt2_y, _ = momentum_vector(pt2, phi2, eta2)

    m_trans_sqrt = (np.sqrt(pt1_x**2 + pt1_y**2) + np.sqrt(pt2_x**2 + pt2_y**2))**2 - (pt1_x + pt2_x)**2 - (pt1_y + pt2_y)**2
    if m_trans_sqrt < 0:
        m_trans_sqrt = 0

    return np.sqrt(m_trans_sqrt)
 def m_trans(evento, comb):
    # Extraer partículas
    prt1 = evento[evento['typ'] == comb[0][0]]
    prt2 = evento[evento['typ'] == comb[1][0]]

    # Filtros por tipo y propiedades
    if comb[0][0] in [1, 2]:
        prt1 = prt1[prt1['ntrk'] == comb[0][2]]
    if comb[1][0] in [1, 2]:
        prt2 = prt2[prt2['ntrk'] == comb[1][2]]

    if comb[0][0] == 4:
            if comb[0][2] == 0:
                prt1 = prt1[prt1['btag'] == comb[0][2]]
            elif comb[0][2] == 1:
                prt1 = prt1[prt1['btag'].isin([1, 2])]
    if comb[1][0] == 4:
            if comb[1][2] == 0:
                prt2 = prt2[prt2['btag'] == comb[1][2]]
            elif comb[1][2] == 1:
                prt2 = prt2[prt2['btag'].isin([1, 2])]

    if not prt1.empty and not prt2.empty:
        pos1 = comb[0][1] - 1
        pos2 = comb[1][1] - 1

        if pos1 < len(prt1) and pos2 < len(prt2):
            p1 = prt1.iloc[pos1]
            p2 = prt2.iloc[pos2]
            return calcular_masa_transversa_numba(p1['pt'], p1['phi'], p1['eta'], p2['pt'], p2['phi'], p2['eta'])
        else:
            return 0
    return 0
#DELTA R
 
 @njit
 def calcular_delta_r_numba(phi1, eta1, phi2, eta2):
    delta_phi = np.abs(phi1 - phi2)
    if delta_phi > np.pi:
        delta_phi = 2 * np.pi - delta_phi

    delta_eta = eta1 - eta2
    return np.sqrt(delta_eta**2 + delta_phi**2)
 def Deltar(evento, comb):
    prt1 = evento[evento['typ'] == comb[0][0]]
    prt2 = evento[evento['typ'] == comb[1][0]]

    if comb[0][0] in [1, 2]:
        prt1 = prt1[prt1['ntrk'] == comb[0][2]]
    if comb[1][0] in [1, 2]:
        prt2 = prt2[prt2['ntrk'] == comb[1][2]]

    if comb[0][0] == 4:
            if comb[0][2] == 0:
                prt1 = prt1[prt1['btag'] == comb[0][2]]
            elif comb[0][2] == 1:
                prt1 = prt1[prt1['btag'].isin([1, 2])] 
    if comb[1][0] == 4:
            if comb[1][2] == 0:
                prt2 = prt2[prt2['btag'] == comb[1][2]]
            elif comb[1][2] == 1:
                prt2 = prt2[prt2['btag'].isin([1, 2])]

    if not prt1.empty and not prt2.empty:
        pos1 = comb[0][1] - 1
        pos2 = comb[1][1] - 1

        if pos1 < len(prt1) and pos2 < len(prt2):
            eta1 = prt1.iloc[pos1]['eta']
            eta2 = prt2.iloc[pos2]['eta']
            phi1 = prt1.iloc[pos1]['phi']
            phi2 = prt2.iloc[pos2]['phi']
            return calcular_delta_r_numba(phi1, eta1, phi2, eta2)

    return 0
#Ratio PT
 def RatioPt(evento,comb):
    prt1 = evento[evento['typ'] == comb[0][0]]
    prt2 = evento[evento['typ']== comb[1][0]]
    if comb[0][0] in [1, 2]:
            prt1 = prt1[prt1['ntrk'] == comb[0][2]]
    if comb[1][0] in [1, 2]:
            prt2 = prt2[prt2['ntrk'] == comb[1][2]]
        # Condición extra para typ 4
    if comb[0][0] == 4:
            if comb[0][2] == 0:
                prt1 = prt1[prt1['btag'] == comb[0][2]]
            elif comb[0][2] == 1:
                prt1 = prt1[prt1['btag'].isin([1, 2])] 
    if comb[1][0] == 4:
            if comb[1][2] == 0:
                prt2 = prt2[prt2['btag'] == comb[1][2]]
            elif comb[1][2] == 1:
                prt2 = prt2[prt2['btag'].isin([1, 2])]
    if not prt1.empty and not prt2.empty:
        # Obtener el pt del primer fotón y de la MET
        #print(posicion1)
        posicion1=comb[0][1]-1
        posicion2=comb[1][1]-1
        if posicion1 < len(prt1) and posicion2 < len(prt2):
        #print(prt1)
          pt_prt1 = prt1.iloc[posicion1]['pt']
          pt_prt2 = prt2.iloc[posicion2]['pt']
          return pt_prt1/pt_prt2
        else:
          return 0
    return 0
#ProductEta
 def ProductEta(evento,comb):
    prt1 = evento[evento['typ'] == comb[0][0]]
    prt2 = evento[evento['typ']== comb[1][0]]
    if comb[0][0] in [1, 2]:
            prt1 = prt1[prt1['ntrk'] == comb[0][2]]
    if comb[1][0] in [1, 2]:
            prt2 = prt2[prt2['ntrk'] == comb[1][2]]
        # Condición extra para typ 4
    if comb[0][0] == 4:
            if comb[0][2] == 0:
                prt1 = prt1[prt1['btag'] == comb[0][2]]
            elif comb[0][2] == 1:
                prt1 = prt1[prt1['btag'].isin([1, 2])] 
    if comb[1][0] == 4:
            if comb[1][2] == 0:
                prt2 = prt2[prt2['btag'] == comb[1][2]]
            elif comb[1][2] == 1:
                prt2 = prt2[prt2['btag'].isin([1, 2])]
    if not prt1.empty and not prt2.empty:
        # Obtener el pt del primer fotón y de la MET
        posicion1=comb[0][1]-1
        posicion2=comb[1][1]-1
        if posicion1 < len(prt1) and posicion2 < len(prt2):
          eta_prt1 = prt1.iloc[posicion1]['eta']
          eta_prt2 = prt2.iloc[posicion2]['eta']
          return eta_prt1*eta_prt2
        else:
          return 0
    return 0
#Dif. eta
 def DifEta(evento,comb):
    prt1 = evento[evento['typ'] == comb[0][0]]
    prt2 = evento[evento['typ']== comb[1][0]]
    if comb[0][0] in [1, 2]:
            prt1 = prt1[prt1['ntrk'] == comb[0][2]]
    if comb[1][0] in [1, 2]:
            prt2 = prt2[prt2['ntrk'] == comb[1][2]]
        # Condición extra para typ 4
    if comb[0][0] == 4:
            if comb[0][2] == 0:
                prt1 = prt1[prt1['btag'] == comb[0][2]]
            elif comb[0][2] == 1:
                prt1 = prt1[prt1['btag'].isin([1, 2])] 
    if comb[1][0] == 4:
            if comb[1][2] == 0:
                prt2 = prt2[prt2['btag'] == comb[1][2]]
            elif comb[1][2] == 1:
                prt2 = prt2[prt2['btag'].isin([1, 2])]
    if not prt1.empty and not prt2.empty:
        # Obtener el pt del primer fotón y de la MET
        posicion1=comb[0][1]-1
        posicion2=comb[1][1]-1
        if posicion1 < len(prt1) and posicion2 < len(prt2):
          eta_prt1 = prt1.iloc[posicion1]['eta']
          eta_prt2 = prt2.iloc[posicion2]['eta']
          return abs(eta_prt1-eta_prt2)
        else:
          return 0
    return 0
#MASA INVARIANTE
 @njit
 def calcular_masa_invariante_numba(pt_array, phi_array, eta_array):
    n = len(pt_array)
    pt_x = np.zeros(n)
    pt_y = np.zeros(n)
    pt_z = np.zeros(n)
    E = np.zeros(n)
    
    for i in range(n):
        px, py, pz = momentum_vector(pt_array[i], phi_array[i], eta_array[i])
        pt_x[i] = px
        pt_y[i] = py
        pt_z[i] = pz
        E[i] = np.sqrt(px**2 + py**2 + pz**2)

    E_total = np.sum(E)
    px_total = np.sum(pt_x)
    py_total = np.sum(pt_y)
    pz_total = np.sum(pt_z)

    m2 = E_total**2 - px_total**2 - py_total**2 - pz_total**2
    return np.sqrt(m2) if m2 > 0 else 0.0
 def m_inv(evento, comb):
    prt = []

    # Filtrado por tipo de partícula
    for c in comb:
        sub_evt = evento[evento['typ'] == c[0]]

        # ntrk si es electrón o muón
        if c[0] in [1, 2]:
            sub_evt = sub_evt[sub_evt['ntrk'] == c[2]]

        # btag si es jet
        if c[0] == 4:
            if c[2] == 0:
                sub_evt = sub_evt[sub_evt['btag'] == 0]
            elif c[2] == 1:
                sub_evt = sub_evt[sub_evt['btag'].isin([1, 2])]

        prt.append(sub_evt)

    # Verificamos que todas las subselecciones no estén vacías
    if all(not p.empty for p in prt):
        pt = []
        phi = []
        eta = []
        for i, p in enumerate(prt):
            pos = comb[i][1] - 1  # posición deseada
            if pos < len(p):
                fila = p.iloc[pos]
                pt.append(fila['pt'])
                phi.append(fila['phi'])
                eta.append(fila['eta'])
            else:
                pt.append(0)
                phi.append(0)
                eta.append(0)

        return calcular_masa_invariante_numba(np.array(pt), np.array(phi), np.array(eta))

    return 0


 @njit
 def calcular_masa_invariante_numba(pt_array, phi_array, eta_array):
    n = len(pt_array)
    pt_x = np.zeros(n)
    pt_y = np.zeros(n)
    pt_z = np.zeros(n)
    E = np.zeros(n)
    
    for i in range(n):
        px, py, pz = momentum_vector(pt_array[i], phi_array[i], eta_array[i])
        pt_x[i] = px
        pt_y[i] = py
        pt_z[i] = pz
        E[i] = np.sqrt(px**2 + py**2 + pz**2)

    E_total = np.sum(E)
    px_total = np.sum(pt_x)
    py_total = np.sum(pt_y)
    pz_total = np.sum(pt_z)

    m2 = E_total**2 - px_total**2 - py_total**2 - pz_total**2
    return np.sqrt(m2) if m2 > 0 else 0.0


 def calculos_eventos(df, lista_num, combinaciones_pares_minv, combinaciones_pares_deltar, combinaciones_pares_mtrans, combinaciones_trios_minv, combinaciones_cuartetos_minv, batch_size=1000):
    masainv = []
    masainv_trios = []
    masainv_cuartetos = []
    masatrans = []
    deltar = []
    no_jets = []
    pt = []
    phi = []
    eta = []
    X_eta=[]
    dif_eta=[]
    Ratio_pt=[]
    total_batches = (len(df) + batch_size - 1) // batch_size  # Calcular el número total de lotes
    with tqdm(total=total_batches, desc="Calculating events") as pbar:
        start = 0
        while start < len(df):
            end = start + batch_size
            # Ajustar el final del lote para no cortar eventos a la mitad
            while end < len(df) and df.iloc[end]['#'] != 0:
                end += 1

            batch_df = df.iloc[start:end]
            current_event = []
            current_event_number = None

            for i, row in batch_df.iterrows():
                if row['#'] == 0:
                    if current_event:
                        event_df = pd.DataFrame(current_event)
                        if func_4 == "1":
                            no_jets.append(Num_jets(event_df))
                        for i in combinaciones_cuartetos_minv:
                            if func_1 == "1":
                               masainv_cuartetos.append(m_inv(event_df, i))
                        for i in combinaciones_trios_minv:
                            if func_1 == "1":
                               masainv_trios.append(m_inv(event_df, i))
                        for i in lista_num_mod:
                            pt.append(pt_part(event_df, i))
                            eta.append(eta_part(event_df, i))
                            phi.append(phi_part(event_df, i))
                        if func_1 == "1":
                           for i in combinaciones_pares_minv:
                                masainv.append(m_inv(event_df, i))
                        if func_2 == "1":
                           for i in combinaciones_pares_mtrans:
                                masatrans.append(m_trans(event_df, i))
                        if func_3 == "1":
                           for i in combinaciones_pares_deltar:
                                deltar.append(Deltar(event_df, i))
                        if func_5 == "1":
                           for i in combinaciones_pares_ratiopt:
                                Ratio_pt.append(RatioPt(event_df, i))
                        if func_6 == "1":
                           for i in combinaciones_pares_prdeta:
                                X_eta.append(ProductEta(event_df, i))
                        if func_7 == "1":
                           for i in combinaciones_pares_difeta:
                                dif_eta.append(DifEta(event_df, i))
                    current_event = []
                    current_event_number = row['#']
                current_event.append(row)

            if current_event:
                event_df = pd.DataFrame(current_event)
                if func_4 == "1":
                    no_jets.append(Num_jets(event_df))
                for i in combinaciones_cuartetos_minv:
                    if func_1 == "1":
                        masainv_cuartetos.append(m_inv(event_df, i))
                for i in combinaciones_trios_minv:
                    if func_1 == "1":
                        masainv_trios.append(m_inv(event_df, i))
                for i in lista_num_mod:
                    pt.append(pt_part(event_df, i))
                    eta.append(eta_part(event_df, i))
                    phi.append(phi_part(event_df, i))
                if func_1 == "1":
                    for i in combinaciones_pares_minv:
                        masainv.append(m_inv(event_df, i))
                if func_2 == "1":
                    for i in combinaciones_pares_mtrans:
                        masatrans.append(m_trans(event_df, i))
                if func_3 == "1":
                    for i in combinaciones_pares_deltar:
                        deltar.append(Deltar(event_df, i))
                if func_5 == "1":
                    for i in combinaciones_pares_ratiopt:
                        Ratio_pt.append(RatioPt(event_df, i))
                if func_6 == "1":
                    for i in combinaciones_pares_prdeta:
                        X_eta.append(ProductEta(event_df, i))
                if func_7 == "1":
                    for i in combinaciones_pares_difeta:
                        dif_eta.append(DifEta(event_df, i))

            start = end
            pbar.update(1)  # Actualizar la barra de progreso
    masainv_trios = np.array(masainv_trios)
    if masainv_trios.size > 0:
        a = int(len(masainv_trios) / len(combinaciones_trios_minv))
        masainv_trios = masainv_trios.reshape(a, -1)
    masainv_cuartetos = np.array(masainv_cuartetos)
    if masainv_cuartetos.size > 0:
        a = int(len(masainv_cuartetos) / len(combinaciones_cuartetos_minv))
        masainv_cuartetos = masainv_cuartetos.reshape(a, -1)
    deltar = np.array(deltar)
    if deltar.size > 0:
        a = int(len(deltar) / len(combinaciones_pares_deltar))
        deltar = deltar.reshape(a, -1)
    X_eta = np.array(X_eta)
    if X_eta.size > 0:
        a = int(len(X_eta) / len(combinaciones_pares_prdeta))
        X_eta = X_eta.reshape(a, -1)
    dif_eta = np.array(dif_eta)
    if dif_eta.size > 0:
        a = int(len(dif_eta) / len(combinaciones_pares_difeta))
        dif_eta = dif_eta.reshape(a, -1)
    Ratio_pt = np.array(Ratio_pt)
    if Ratio_pt.size > 0:
        a = int(len(Ratio_pt) / len(combinaciones_pares_ratiopt))
        Ratio_pt = Ratio_pt.reshape(a, -1)
    phi = np.array(phi)
    if phi.size > 0:
        a = int(len(phi) / len(lista_num))
        phi = phi.reshape(a, -1)
    eta = np.array(eta)
    if eta.size > 0:
        a = int(len(eta) / len(lista_num))
        eta = eta.reshape(a, -1)
    pt = np.array(pt)
    if pt.size > 0:
        a = int(len(pt) / len(lista_num))
        pt = pt.reshape(a, -1)
    masainv = np.array(masainv)
    if masainv.size > 0:
        a = int(len(masainv) / len(combinaciones_pares_minv))
        masainv = masainv.reshape(a, -1)
    masatrans = np.array(masatrans)
    if masatrans.size > 0:
        b = int(len(masatrans) / len(combinaciones_pares_mtrans))
        masatrans = masatrans.reshape(b, -1)

    columtrios = []
    columcuartetos = []
    columpares = []
    columpares1 = []
    columpares2 = []
    columpares3 = []
    columpares4 = []
    columpares5 = []
    colum = []
    colum1 = []
    colum2 = []
    for i in lista_num_names:
        cadena = tupla_a_cadena(i)
        colum.append('Pt ' + cadena)
        colum1.append('Eta ' + cadena)
        colum2.append('Phi ' + cadena)
    for i in comb_pares_names_minv:
        cadena = tupla_a_cadena(i)
        columpares.append('m_inv ' + cadena)
    for i in comb_pares_names_mtrans:
        cadena = tupla_a_cadena(i)
        columpares1.append('m_trans ' + cadena)
    for i in comb_pares_names_deltar:
        cadena = tupla_a_cadena(i)
        columpares2.append('deltaR ' + cadena)
    for i in comb_trios_names_minv:
        cadena = tupla_a_cadena(i)
        columtrios.append('m_inv ' + cadena)
    for i in comb_cuartetos_names_minv:
        cadena = tupla_a_cadena(i)
        columcuartetos.append('m_inv ' + cadena)
    for i in comb_pares_names_ratiopt:
        cadena = tupla_a_cadena(i)
        columpares3.append('PT1/PT2'+ cadena)
    for i in comb_pares_names_prdeta:
        cadena = tupla_a_cadena(i)
        columpares4.append('Eta1*Eta2' + cadena)
    for i in comb_pares_names_difeta:
        cadena = tupla_a_cadena(i)
        columpares5.append('Eta Separation' + cadena)
    # Crear DataFrames solo si los arrays no están vacíos
    csv_columtrios = pd.DataFrame(masainv_trios, columns=columtrios) if masainv_trios.size > 0 else pd.DataFrame()
    csv_columcuartetos = pd.DataFrame(masainv_cuartetos, columns=columcuartetos) if masainv_cuartetos.size > 0 else pd.DataFrame()
    csv_deltar = pd.DataFrame(deltar, columns=columpares2) if deltar.size > 0 else pd.DataFrame()
    csv_pt = pd.DataFrame(pt, columns=colum) if pt.size > 0 else pd.DataFrame()
    csv_eta = pd.DataFrame(eta, columns=colum1) if eta.size > 0 else pd.DataFrame()
    csv_phi = pd.DataFrame(phi, columns=colum2) if phi.size > 0 else pd.DataFrame()
    csv_minv = pd.DataFrame(masainv, columns=columpares) if masainv.size > 0 else pd.DataFrame()
    csv_mtrans = pd.DataFrame(masatrans, columns=columpares1) if masatrans.size > 0 else pd.DataFrame()
    csv_ratiopt = pd.DataFrame(Ratio_pt, columns=columpares3) if Ratio_pt.size > 0 else pd.DataFrame()
    csv_prdeta = pd.DataFrame(X_eta, columns=columpares4) if X_eta.size > 0 else pd.DataFrame()
    csv_difeta = pd.DataFrame(dif_eta, columns=columpares5) if dif_eta.size > 0 else pd.DataFrame()
    # Concatenar solo los DataFrames que no están vacíos
    csv_combined = pd.concat([csv_phi, csv_eta, csv_pt, csv_minv, csv_mtrans, csv_deltar, csv_columtrios, csv_columcuartetos,csv_ratiopt,csv_prdeta,csv_difeta], axis=1)
    if func_4 == "1": 
     csv_combined["No_jets"] = no_jets
    #print(no_jets)
    return csv_combined

# Aplicar la función a ambos DataFrames
 csv_sig = calculos_eventos(filtered_dfsg, lista_num, combinaciones_pares_minv, combinaciones_pares_deltar, combinaciones_pares_mtrans, combinaciones_trios_minv, combinaciones_cuartetos_minv)
 csv_sig['Td'] = "s"
 if evit != 1 :
        csv_bg = calculos_eventos(filtered_dfbg, lista_num, combinaciones_pares_minv, combinaciones_pares_deltar, combinaciones_pares_mtrans, combinaciones_trios_minv, combinaciones_cuartetos_minv)
        csv_bg['Td'] = "b"
        name_bg=input("Enter the name with which you want to save the background results, this can be useful to speed up the process if you want to analyze another case with the same background: ")
        name_bg=name_bg + ".csv"
        csv_bg.to_csv(name_bg, index=False)
        print(f"The background analysis was saved in case it will be used in future calculations so that it is not necessary to recalculate. It was saved with the name: {name_bg}")
 if evit == 1 :
        csv_bg=filtered_dfbg
 df_combined = pd.concat([csv_bg, csv_sig], ignore_index=False)

# Mantener la numeración de la primera columna
 df_combined.reset_index(drop=True, inplace=True)
 df_combined.index += 1

# Guardar la base de datos combinada
 df_combined = df_combined.rename_axis('Event').reset_index()
 df_combined.to_csv(Final_name, index=False)

 print(f'The file was created with the name: {Final_name}')
 print("Now the BDT training process will begin, the final file will be overwritten on the one already created.")
#INICIA PROCESO DE GRAFICADO
 results_df = pd.read_csv(Final_name)
signal_df = results_df[results_df['Td'] == 's']
background_df = results_df[results_df['Td'] == 'b']
# Definir las columnas a verificar (excluyendo la primera y la última columna)
columns_to_check = df_combined.columns[1:-1]

# Función para crear histogramas y guardar la gráfica
def crear_histograma(df_signal, df_background, columna, xlabel, ylabel, title, binsopt, rango_min, rango_max, filename=None):
    # Usar la primera columna para los pesos
    primera_columna = df_signal.columns[0]
    plt.hist(df_signal[columna],bins=binsopt, range=(rango_min, rango_max), edgecolor='black', alpha=0.5, label='Signal', density=True)
    #plt.hist(df_signal[columna], bins=binsopt, range=(rango_min, rango_max), edgecolor='black', alpha=0.5, label='Signal')
    #plt.hist(df_background[columna], bins=binsopt, range=(rango_min, rango_max), edgecolor='black', alpha=0.5, label='Background')
    plt.hist(df_background[columna], bins=binsopt, range=(rango_min, rango_max), edgecolor='black', alpha=0.5, label='Background', density=True)
    plt.grid(True)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.title(title)
    plt.legend(loc='upper right')
    if filename:
        plt.savefig(filename)
    plt.show()

while True:
    # Imprimir los nombres de las columnas
    print("Available column names:")
    for columna in columns_to_check:
        print(columna)

    # Preguntar al usuario cuál gráfica quiere
    columna_seleccionada = input("Please enter the name of the column you want to plot (or 'exit' to finish): ")
    
    if columna_seleccionada.lower() == 'exit':
        break

    # Preguntar al usuario el número de bins y verificar que sea positivo
    while True:
        try:
            binsopt = int(input("Please enter the number of bins for the histogram (must be a positive integer): "))
            if binsopt > 0:
                break
            else:
                print("The number of bins must be a positive integer. Try again.")
        except ValueError:
            print("Please enter a valid integer.")

    # Preguntar al usuario el rango mínimo y máximo para la columna seleccionada
    while True:
        try:
            rango_min = float(input(f"Please enter the minimum range for the column: {columna_seleccionada}: "))
            rango_max = float(input(f"Please enter the maximum range for the column: {columna_seleccionada}: "))
            if rango_min < rango_max:
                break
            else:
                print("The minimum range must be less than the maximum range. Please try again.")
        except ValueError:
            print("Please enter valid numeric values for the range.")

    # Crear el histograma para la columna seleccionada sin guardar
    crear_histograma(signal_df, background_df, columna_seleccionada, columna_seleccionada, 'N.Events',f'{columna_seleccionada} vs N. Events', binsopt, rango_min, rango_max, None)

    # Preguntar al usuario si desea guardar la gráfica
    guardar_grafica = input("Do you want to save the graph? (yes/no):")
    
    if guardar_grafica.lower() == 'yes':
        # Preguntar al usuario el título para la gráfica
        name_graphic = input("Insert the title you want to put for the graph: ")
        # Preguntar al usuario el nombre del archivo para guardar la gráfica
        nombre_archivo = input("Please enter the name of the file to save the graph: ")
        nombre_archivo = nombre_archivo + ".jpg"

        # Crear el histograma para la columna seleccionada y guardar la gráfica
        crear_histograma(signal_df, background_df, columna_seleccionada, columna_seleccionada,"N.Events", name_graphic, binsopt, rango_min, rango_max, nombre_archivo)
to_signif=input("Do you want to skip directly to the significance calculus(you must have the .csv trained) ? Yes=1, No=0:")
if to_signif== "0":
 print("Start procces for BDT")
#INICIA PROCESO PARA BDT
# Separar la primera fila (títulos de las columnas)
 column_titles = df_combined.iloc[0]

# Ordenar aleatoriamente las filas a excepción de la primera
 df_shuffled = df_combined.iloc[1:].sample(frac=1).reset_index(drop=True)

# Volver a agregar la primera fila (títulos de las columnas)
 df_shuffled.loc[-1] = column_titles
 df_shuffled.index = df_shuffled.index + 1
 df_shuffled = df_shuffled.sort_index()   #ESTE VA A LLEVAR LA INFORMACION JUNTA Y MEZCLADA
 def roc(test_x,test_y,train_x,train_y, model):
    """"
    It presents the roc curve, which shows the accuracy of the classifier, 
    the closer the area 1, the better the classifier.   """
    plt.figure(figsize=(10,7))
    plt.title('ROC curve', fontsize=20)
    model_predict = model.predict_proba(test_x)
    model_predict = model_predict[:,1]
    auc_score = roc_auc_score(test_y, model_predict)
    fpr, tpr, _ = roc_curve(test_y, model_predict) #roc_curve(true binary labels, prediction scores)
    print('Test : ', auc_score)
    plt.plot(tpr, 1-fpr, label='Test   '+ str(round(auc_score, 4)), color='firebrick', linewidth=2)

    model_predict = model.predict_proba(train_x)
    model_predict = model_predict[:,1]
    auc_score = roc_auc_score(train_y, model_predict)
    fpr, tpr, _ = roc_curve(train_y, model_predict)
    plt.plot(tpr, 1-fpr, label='Train   ' + str(round(auc_score,4)) , color='midnightblue', linewidth=2)
    print('Train : ', auc_score)
    plt.legend(loc='best',fontsize=20)
    plt.ylabel('Purity', fontsize=20)
    plt.xlabel('Efficiency', fontsize=20)
    #plt.yscale('log')
    #plt.xscale('log')
    plt.ylim(0.7,1.1)
    #plt.show()
    plt.grid(True)
    plt.xticks(fontsize = 15); 
    plt.yticks(fontsize = 15); 
    nombre=input("Enter the name with which you want to save the image containing the ROC curve obtained for the training model: ")
    nombre= nombre + ".jpg"
    plt.savefig(nombre)

 def plot_classifier_distributions(model, test, train, cols, print_params=False, params=None):
    global _ks_back
    global _ks_sign
    test_background = model.predict_proba(test.query('label==0')[cols])[:,1]
    test_signal     = model.predict_proba(test.query('label==1')[cols])[:,1]
    train_background= model.predict_proba(train.query('label==0')[cols])[:,1]
    train_signal    = model.predict_proba(train.query('label==1')[cols])[:,1]

    test_pred = model.predict_proba(test[cols])[:,1]
    train_pred= model.predict_proba(train[cols])[:,1]

    density = True
    fig, ax = plt.subplots(figsize=(10, 7))
    background_color = 'firebrick'
    opts = dict(
        range=[0,1],
        bins = 50,#previously its value was 25
        density = density
    )
    histtype1 = dict(
        histtype='step',
        linewidth=1,
        alpha=1,
    )

    ax.hist(train_background, **opts, **histtype1,
             facecolor=background_color,
             edgecolor=background_color,
             zorder=0)
    ax.hist(train_signal, **opts, **histtype1,
             facecolor='blue',
             edgecolor='blue',
             zorder=1000)

    hist_test_0 = np.histogram(test_background, **opts)
    hist_test_1 = np.histogram(test_signal, **opts)
    bins_mean = (hist_test_0[1][1:]+hist_test_0[1][:-1])/2
    bin_width = bins_mean[1]-bins_mean[0]
    area0 = bin_width*np.sum(test.label==0)
    area1 = bin_width*np.sum(test.label==1)

    opts2 = dict(
          capsize=3,
          ls='none',
          marker='P'
    )
   

    ax.errorbar(bins_mean, hist_test_0[0],  yerr = np.sqrt(hist_test_0[0]/area0), xerr=bin_width/2,
                 color=background_color, **opts2, zorder=100)
    ax.errorbar(bins_mean, hist_test_1[0],  yerr = np.sqrt(hist_test_1[0]/area1), xerr=bin_width/2,
                 color='midnightblue', **opts2, zorder=10000)

    # Aplicar el test KS
    ##statistic, p_value = ks_2samp(data1, data2)
    _ks_back = ks_2samp(train_background, test_background)[1]
    _ks_sign = ks_2samp(train_signal, test_signal)[1]

    auc_test  = roc_auc_score(test.label,test_pred )
    auc_train = roc_auc_score(train.label,train_pred)

    legend_elements = [Patch(facecolor='black', edgecolor='black', alpha=0.4,
                             label=f'Train : {round(auc_train,8)}'),
                      Line2D([0], [0], marker='|', color='black',
                             label=f'Test : {round(auc_test,8)}',
                              markersize=25, linewidth=1),
                       Circle((0.5, 0.5), radius=2, color='red',
                              label=f'Background (ks-pval) : {round(_ks_back,8)}',),
                       Circle((0.5, 0.5), 0.01, color='blue',
                              label=f'Signal (ks-pval) : {round(_ks_sign,8)}',),
                       ]

    ax.legend(
              #title='KS test',
              handles=legend_elements,
              #bbox_to_anchor=(0., 1.02, 1., .102),
              loc='upper center',
              ncol=2,
              #mode="expand",
              #borderaxespad=0.,
              frameon=True,
              fontsize=15)

    if print_params:
        ax.text(1.02, 1.02, params_to_string(model),
        transform=ax.transAxes,
      fontsize=13, ha='left', va='top')

    ax.set_yscale('log')
    ax.set_xlabel('BDT prediction',fontsize=20)
    plt.ylabel('Events',fontsize=20);
    ax.set_ylim(0.0001, 100)
    plt.xticks(fontsize = 15); 
    plt.yticks(fontsize = 15); 


    #plt.savefig(os.path.join(dir_, 'LR_overtrain.pdf'), bbox_inches='tight')
    return fig, ax

 print('Size of data: {}'.format(df_shuffled.shape))
 print('Number of events: {}'.format(df_shuffled.shape[0]))
#print('Number of columns: {}'.format(df_shuffled.shape[1]))

#print ('\nList of features in dataset:')
#for col in df_shuffled.columns:
#    print(col)

 print('Number of signal events: {}'.format(len(df_shuffled[df_shuffled.Td == 's'])))
 print('Number of background events: {}'.format(len(df_shuffled[df_shuffled.Td == 'b'])))
 print('Fraction signal: {}'.format(len(df_shuffled[df_shuffled.Td == 's'])/(float)(len(df_shuffled[df_shuffled.Td == 's']) + len(df_shuffled[df_shuffled.Td == 'b']))))

 factor=int(input("It is recommended to have a fraction signal=0.5, to what extent will the amount of data be limited for both background and signal: ")) 
# Get the 's' and 'b' 
 s_events = df_shuffled[df_shuffled['Td'] == 's'].head(factor)  # specified number of signal events
 b_events = df_shuffled[df_shuffled['Td'] == 'b'].head(factor)  #specified number of background events

# Combining filtered signal and background datasets for training
 df_shuffled = pd.concat([s_events, b_events], ignore_index=True)

 print('Number of signal events: {}'.format(len(df_shuffled[df_shuffled.Td == 's'])))
 print('Number of background events: {}'.format(len(df_shuffled[df_shuffled.Td == 'b'])))
 print('Fraction signal: {}'.format(len(df_shuffled[df_shuffled.Td == 's'])/(float)(len(df_shuffled[df_shuffled.Td == 's']) + len(df_shuffled[df_shuffled.Td == 'b']))))

 Sig_df = (df_shuffled[df_shuffled.Td == 's'])
 Bkg_df = (df_shuffled[df_shuffled.Td == 'b'])
 vars_for_train = Sig_df.columns
 vars_for_train = vars_for_train.drop(["Td", "Event"])
 vars_for_train = vars_for_train.to_list()
 print(vars_for_train)
 data4label   = df_shuffled[vars_for_train]
 signal4train = Sig_df[vars_for_train]
 bkg4train    = Bkg_df[vars_for_train]
 correlations = signal4train.corr()
 print(correlations)
 # Checking for variables with high correlation
 # Select upper triangle of correlation matrix
 upper = correlations.where(np.triu(np.ones(correlations.shape), k=1).astype(bool))

# Find features with correlation greater than 0.95
 to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]

#Filter the columns to drop, keeping present in the DataFrame
 to_drop_filtered = [column for column in to_drop if column in signal4train.columns]

#Drop features without using inplace=True to avoid SettingWithCopyWarning
 signal4train = signal4train.drop(to_drop_filtered, axis=1)

#same for bkg4train
 bkg4train = bkg4train.drop(to_drop_filtered, axis=1)
 print(f"Se borraran las siguientes columnas dadas su correlacion :  {to_drop}")
 vars_for_train = list(vars_for_train)
 for var in to_drop:
    vars_for_train.remove(var)
 data4label   = df_shuffled[vars_for_train]
 signal4train = Sig_df[vars_for_train]
 bkg4train    = Bkg_df[vars_for_train]
 n_samples = min(signal4train.shape[0], bkg4train.shape[0])
 bkg4train = bkg4train.sample(n=n_samples, random_state=42)
 #copy
 bkg4train = bkg4train.copy()
 signal4train = signal4train.copy()

#assignments
 bkg4train.loc[:, 'signal/bkgnd'] = 0
 signal4train.loc[:, 'signal/bkgnd'] = 1

# Concatenate the DataFrames
 df_4train = pd.concat([signal4train, bkg4train])
#GENERAL DATA
# separate the labels and the features
 features_ = df_4train.drop(['signal/bkgnd'], axis=1) #train_x features = all minus (signal/bkgnd and masses)
 label_    = df_4train['signal/bkgnd']   #train_Y
#SIGNAL
 signal_features = signal4train.drop(['signal/bkgnd'], axis=1) #signal_x
 signal_label    = signal4train['signal/bkgnd'] #signal_y
#BKGND
 bkgnd_features = bkg4train.drop(['signal/bkgnd'], axis=1) # bkgnd_x
 bkgnd_labels   = bkg4train['signal/bkgnd'] # bkgnd_y
 test=input("The training will be performed with a default proportion of 0.8 for training, do you want to change it? Yes=1, No=0: ")
#SIGNAL
 size=0.8
 if test == "1" :
    size=input("Enter the value of the new proportion for training (previously it was 0.8): ")
    size=float(size)
 
 train_sig_feat, test_sig_feat, train_sig_lab, test_sig_lab = train_test_split(signal_features, signal_label,
                                                  test_size=size,
                                                  random_state=1)
#BKGND IZQ
 train_bkg_feat, test_bkg_feat, train_bkg_lab, test_bkg_lab = train_test_split(bkgnd_features, bkgnd_labels,
                                                  test_size=size,
                                                  random_state=1)
 test_feat = pd.concat([test_sig_feat, test_bkg_feat]) # test_x
 test_lab = pd.concat([test_sig_lab, test_bkg_lab]) # test_y
 train_feat = pd.concat([train_sig_feat, train_bkg_feat]) # train_x
 train_lab = pd.concat([train_sig_lab, train_bkg_lab]) # train_y

 eval_set = [(train_feat, train_lab), (test_feat, test_lab)]
 test = test_feat.assign(label=test_lab)
 train = train_feat.assign(label=train_lab)
 cols = vars_for_train
#Calculo para los mejores hiperparametros
 _ks_back = 0
 _ks_sign = 0
 while _ks_back < 0.05 or _ks_sign < 0.05:
    manual_params = {
        'colsample_bylevel': 0.8129556523950925,
         'colsample_bynode': 0.6312324405171867,
         'colsample_bytree': 0.6479261529614907,
         'gamma': 6.0528983610080305,
         'learning_rate': 0.1438821307939924,
         'max_leaves': 15,               
         'max_depth': 5,
         'min_child_weight': 1.385895334160164,
         'reg_alpha': 6.454459356576733,
         'reg_lambda': 22.88928659795952,
         'n_estimators':100
    }

    #Parameters close to manual parameters
    def objective(trial):
        params = {
            'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.7, 0.9),  
            'colsample_bynode': trial.suggest_float('colsample_bynode', 0.6, 0.7),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.7),
            'gamma': trial.suggest_float('gamma', 5.5, 7), 
            'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.2), 
            'max_leaves': trial.suggest_int('max_leaves', 10, 20), 
            'max_depth': trial.suggest_int('max_depth', 4, 6), 
            'min_child_weight': trial.suggest_float('min_child_weight', 1.0, 2.0), 
            'reg_alpha': trial.suggest_float('reg_alpha', 6, 7), 
            'reg_lambda': trial.suggest_float('reg_lambda', 22, 23), 
            'n_estimators': trial.suggest_int('n_estimators', 90, 120) 
        }
        model = xgb.XGBClassifier(
            objective='binary:logistic',
            tree_method='hist',
            **params
        )
        model.fit(train_feat[cols], train_lab)
        preds = model.predict_proba(test_feat[cols])[:, 1]
        return roc_auc_score(test_lab, preds)

# including manual parameters as initial trial
    study = optuna.create_study(direction='maximize')
    study.enqueue_trial(manual_params)  
    study.optimize(objective, n_trials=50) #optimizing

#Print results
    print("Best parameters:", study.best_trial.params)
    print("Best score:", study.best_trial.value)
# Guardar los mejores hiperparámetros
    best_hyperparams = study.best_trial.params
    # Fill missing values in training and testing data with the mean of the training features
    train_feat[cols] = train_feat[cols].fillna(train_feat[cols].mean())
    test_feat[cols] = test_feat[cols].fillna(train_feat[cols].mean())

# Create evaluation set with consistent feature columns
    eval_set = [(train_feat[cols], train_lab), (test_feat[cols], test_lab)]

# Asignar automáticamente los mejores hiperparámetros en el modelo
    model = xgb.XGBClassifier(
        objective='binary:logistic',
        tree_method='hist',
        **best_hyperparams
    )
    # Define and fit the XGBoost model with early stopping in the constructor
    modelv1 = xgb.XGBClassifier(
        objective='binary:logistic',
        tree_method='hist',
        n_jobs=5,
        max_leaves=best_hyperparams['max_leaves'],
        max_depth=best_hyperparams['max_depth'],
        learning_rate=best_hyperparams['learning_rate'],
        reg_alpha=best_hyperparams['reg_alpha'],
        reg_lambda=best_hyperparams['reg_lambda'],
        min_child_weight=best_hyperparams['min_child_weight'],
        colsample_bylevel=best_hyperparams['colsample_bylevel'],
        colsample_bynode=best_hyperparams['colsample_bynode'],
        colsample_bytree=best_hyperparams['colsample_bytree'],
        gamma=best_hyperparams['gamma'],
        n_estimators=best_hyperparams['n_estimators'],
        early_stopping_rounds=10
    )
    
    # Fit the model with the corrected eval_set and verbose turned off
    modelv1.fit(train_feat[cols], train_lab, eval_set=eval_set, verbose=False)
    fig, ax = plot_classifier_distributions(modelv1, test=test, train=train, cols = cols, print_params=False)
    #ax.set_title(r'Total sample size $\approx$ '+str(len(train) + len(test))+' optimized')
    print(f'Background(Ks-pval): {_ks_back}')
    print(f'Signal(Ks-pval): {_ks_sign}')
 name_dist=input("Enter the name with which you want to save the graph that will be created as the result of the classifier: ")
 plt.savefig(name_dist + '.png')
#plt.savefig('classifier_distribution.pdf')
 plt.show()

 roc(test_feat[cols], test_lab, train_feat[cols], train_lab, modelv1)
 print("A graph will now be shown that organizes the variables used by the model in order of importance (F Score): ")
 plt.figure(figsize=(16, 12))
 xgb.plot_importance(modelv1)
# Obtener los nombres de las características
 ax = plt.gca()
 labels = [item.get_text() for item in ax.get_yticklabels()]

# Dividir los títulos largos en dos renglones
 new_labels = []
 for label in labels:
    if len(label) > 20:  # Ajusta este valor según sea necesario
        parts = label.split(' ')
        mid = len(parts) // 2
        new_label = ' '.join(parts[:mid]) + '\n' + ' '.join(parts[mid:])
        new_labels.append(new_label)
    else:
        new_labels.append(label)

# Asignar los nuevos títulos
 ax.set_yticklabels(new_labels)

# Ajustar el tamaño de la fuente y el espaciado
 plt.yticks(fontsize=10)
 plt.subplots_adjust(left=0.3, right=0.9)  # Ajusta estos valores según sea necesario
 save=input("Do you want to save the image? Yes=1, No=0?: ")
 if save == "1":
    name_save=input("Enter the name with which you want to save it: ")
    plt.savefig(name_save + '.png', bbox_inches='tight')
 plt.show()
 pickle.dump(modelv1, open(f"model_xgbv1_opt.dat", "wb"))

 Mymodel = pickle.load(open(f"model_xgbv1_opt.dat", "rb")) 

 def mycsvfile(pdf, myname):
    """ this function will embedded the variable xgb in our dataset. """
    selected_vars = cols
    datalabel = pdf[selected_vars]
    
    ##
    predict = Mymodel.predict_proba(datalabel)
    
    ##
    pdf['XGB'] = predict[:,1]
    
    ## DataTable
    table_df = dt.Frame(pdf)
    table_df.to_csv(myname)
 mycsvfile(df_shuffled,Final_name)
 print(f'The file was created with the name: {Final_name}')
if to_signif== "1":
    df_path = input("Enter the path of the previously calculated DataFrame:")
    df_shuffled = pd.read_csv(df_path)
#INICIA EL CALCULO DE SIGNIFICANCIA
if to_signif== "0":
    df_shuffled=pd.read_csv(Final_name)
pass1=input("To continue with the significance calculus you can add minimum requirements for your data , example, you can limit Pt>150. The columns to which the limit can be applied will be shown, if you do not wanna apply this minimum filter enter 0(No), if you want apply enter 1(yes): ")
if  pass1 == "1" or pass1== "yes" :
     vars_for_train = df_shuffled.columns
     vars_for_train = vars_for_train.drop(["Td", "Event"])
     print(f"The colums to do the minimum filter are: ")
     for columna in vars_for_train:
        print(columna)
     vars_for_train = vars_for_train.to_list()

     while True:
        column = input("Enter the column title to apply the limit (or type 'exit' to finish): ")
        if column.lower() == 'exit':
            break
        if column not in vars_for_train:
            print(f"Column '{column}' is not valid. Please choose from: {vars_for_train}.")
            for columna in vars_for_train:
                 print(columna)
            continue
        filter_type = input("Do you want to apply a minimum limit, exclude a range, or apply an interval? (type 'exclude' for range exclusion, or 'interval' for applying an interval): ")
        if filter_type.lower() == 'exclude':
            lower_limit = float(input(f"Enter the lower limit of the range to exclude for {column}: "))
            upper_limit = float(input(f"Enter the upper limit of the range to exclude for {column}: "))
            df_shuffled = df_shuffled[(df_shuffled[column] < lower_limit) | (df_shuffled[column] > upper_limit)]
        elif filter_type.lower() == 'interval':
            lower_limit = float(input(f"Enter the lower limit of the interval for {column}: "))
            upper_limit = float(input(f"Enter the upper limit of the interval for {column}: "))
            df_shuffled = df_shuffled[(df_shuffled[column] >= lower_limit) & (df_shuffled[column] <= upper_limit)]
        else:
            print("Invalid filter type. Please choose 'min', 'exclude', or 'interval'.")
            continue
        print("Filter applied")
     save1=input("Do you wanna save the new data whit these minimum filters 1(yes) 0(no): ")
     if save1 == "1" :
        save_nom=input("Enter the name that will now save the data filtered : ")
        df_shuffled.to_csv(save_nom + '.csv', index=False)
else:
     print("No minimum filter applied.")

print('Number of signal events: {}'.format(len(df_shuffled[df_shuffled.Td == 's'])))
print('Number of background events: {}'.format(len(df_shuffled[df_shuffled.Td == 'b'])))
print('Fraction signal: {}'.format(len(df_shuffled[df_shuffled.Td == 's'])/(float)(len(df_shuffled[df_shuffled.Td == 's']) + len(df_shuffled[df_shuffled.Td == 'b']))))

factor=int(input("It is recommended to have a fraction signal=0.5, to what extent will the amount of data be limited for both background and signal: ")) 
s_events = df_shuffled[df_shuffled['Td'] == "s"].head(factor)  # specified number of signal events
b_events = df_shuffled[df_shuffled['Td'] == "b"].head(factor)  #specified number of background events

# Combining filtered signal and background datasets for training
df_shuffled = pd.concat([s_events, b_events], ignore_index=True)

XSsignal = float(input("Enter the cross section of the signal in pb: ")) # Sección eficaz de la señal
XSbackground = float(input("Enter the cross section of the background in pb: "))  # Sección eficaz del background

#Cortes para requisitos minimos 

def CalSig(mypdf, xgbcut,IntLumi,XSs,XSb):
    mypdf = mypdf[mypdf['XGB'] > xgbcut]  # Filtrar los datos

    Ns_csv = len(mypdf[mypdf.Td == "s"])
    Nb_csv = len(mypdf[mypdf.Td == "b"])
    fraction_csv_s = Ns_csv / factor
    fraction_csv_b = Nb_csv / factor
    pbTOfb = 1000  # factor conversión de pb a fb
    #IntLumi = 3000  # Luminosidad integrada
    alpha = XSs * pbTOfb * IntLumi / factor # Factor de escalamiento de los eventos generados a eventos calculados de la señal
    beta = XSb * pbTOfb * IntLumi / factor  # Factor de escalamiento de los eventos generados a eventos calculados del background

    try:
        Sig = (alpha * Ns_csv) / (math.sqrt((alpha * Ns_csv) + (beta * Nb_csv)))
    except ZeroDivisionError:
        print("Division by zero detected. Continuing with the next calculation.")
        Sig = float(0)  # O cualquier valor que consideres apropiado para manejar el error
    print('Number of signal events: {}'.format(len(mypdf[mypdf.Td == 's'])))
    print('Number of background events: {}'.format(len(mypdf[mypdf.Td == 'b'])))
    print(f'The obtained significance is :{Sig},with an XGB cut at :{xgbcut}')
    return Sig

def main():
    global results_df
    data = df_shuffled  # Cargar los datos desde un archivo CSV

    Sigval = []
    XGBval = []
    LumiVal = []
    while True:
     user_input = input("Enter start, stop, and step values separated by spaces (e.g. 300 3100 100): ")
    
     parts = user_input.split()
    
     if len(parts) != 3:
        print("Error: You must enter exactly 3 values separated by spaces.")
        continue  # Ask again
     try:
        start, stop, step = map(int, parts)
        break  # Exit loop if successful
     except ValueError:
        print("Error: All values must be integers.")
        continue  # Ask again
    for IntLumi in range(start, stop, step):  # Loop for IntLumi from 300 to 3000 in steps of 100
        #print(f'\nLuminosity = {IntLumi}')
        xgbi = 0.5
        for jj in range(100):
            Sigval.append(CalSig(data, xgbi, IntLumi,XSsignal,XSbackground))
            XGBval.append(xgbi)
            LumiVal.append(IntLumi)
            xgbi = xgbi + 0.005
    maxsig = max(Sigval)
    myindex = Sigval.index(max(Sigval))
    valxgb = XGBval[myindex]
    vallumi = LumiVal[myindex]
    #print("------ XGB cut")
    print("\nMax Significance value is {:.3f}, for XGB cut {:.3f} at Luminosity {:.0f}".format(round(maxsig, 3), round(valxgb, 3), vallumi))

    # Convert lists to numpy arrays for plotting
    LumiVal = np.array(LumiVal)
    XGBval = np.array(XGBval)
    Sigval = np.array(Sigval)

    # Create grid for contour plot
    lumi_vals_unique = np.unique(LumiVal)
    xgb_vals_unique = np.unique(XGBval)
    LumiGrid, XGBGrid = np.meshgrid(lumi_vals_unique, xgb_vals_unique)
    SigGrid = np.zeros_like(LumiGrid, dtype=float)

    for i in range(LumiGrid.shape[0]):
        for j in range(LumiGrid.shape[1]):
            mask = (LumiVal == LumiGrid[i, j]) & (XGBval == XGBGrid[i, j])
            if np.any(mask):
                SigGrid[i, j] = Sigval[mask][0]
    results_df = pd.DataFrame({
        'Luminosity': LumiVal,
        'XGB Cut': XGBval,
        'Significance': Sigval
    })

    # Guardar el DataFrame en un archivo CSV
    sig_nom=input("Enter the name that will now save the significance calculations: ")
    results_df.to_csv(sig_nom + '.csv', index=False)
    print(f"Results save in ", sig_nom )
    plt.figure(figsize=(10, 6))
    contour = plt.contourf(LumiGrid, SigGrid, XGBGrid, levels=20, cmap='viridis')
    cbar = plt.colorbar(contour)  # colorbar
    cbar.set_label('XGB Cut', fontsize=30)  
    cbar.ax.tick_params(labelsize=22) 
    titulo=input("Enter the title you want to add to the graph (it will contain luminosity, significance, and XGB cut as variables): ")
    plt.xlabel('Luminosity (fb$^{-1}$)', fontsize=30)
    plt.ylabel('Significance', fontsize=30)
    plt.tick_params(axis='both', which='major', labelsize=22)  # size of axis numbers
    plt.title(titulo)
    plt.grid(True)
    name_graphic_sig=input("Enter the name to save the graph: ")
    plt.savefig(name_graphic_sig + '.jpg', bbox_inches='tight')
    plt.show()

if __name__ == '__main__':
    main()

